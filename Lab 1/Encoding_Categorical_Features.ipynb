{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1C - Encoding Categorical Features in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.0.3-bin-hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "print(findspark.find())\n",
    "findspark.init('C:\\Spark\\spark-3.0.3-bin-hadoop2.7') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://CT-LP-234.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Lab-01_C_Encoding_categorical_features</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29afe1c0fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "##sc1 = SparkContext(\"local\",\"Lab-01_C_Encoding Categorical Features\")\n",
    "sc1 = SparkSession.builder.appName(\"Lab-01_C_Encoding_categorical_features\").getOrCreate()\n",
    "sc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  0|       a|\n",
      "|  1|       b|\n",
      "|  2|       c|\n",
      "|  3|       a|\n",
      "|  4|       a|\n",
      "|  5|       c|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sc1.createDataFrame(\n",
    "    [(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\")],\n",
    "    [\"id\", \"category\"])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StringIndexer <br>\n",
    "StringIndexer encodes a string column of labels to a column of label indices. <br>\n",
    "Four ordering options are supported: <br>\n",
    "1. “frequencyDesc”: descending order by label frequency (most frequent label assigned 0), \n",
    "2. “frequencyAsc”: ascending order by label frequency (least frequent label assigned 0), \n",
    "3. “alphabetDesc”: descending alphabetical order, and \n",
    "4. “alphabetAsc”: ascending alphabetical order (default = “frequencyDesc”). <br>\n",
    "\n",
    "Note that in case of equal frequency when under “frequencyDesc”/”frequencyAsc”, the strings are further sorted by alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| id|category|categoryIndex|\n",
      "+---+--------+-------------+\n",
      "|  0|       a|          2.0|\n",
      "|  1|       b|          1.0|\n",
      "|  2|       c|          0.0|\n",
      "|  3|       a|          2.0|\n",
      "|  4|       a|          2.0|\n",
      "|  5|       c|          0.0|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\", stringOrderType='alphabetDesc')\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoder <br>\n",
    "\n",
    "One-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values.\n",
    "\n",
    "For string type input data, it is common to encode categorical features using StringIndexer first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|categoryIndex1|categoryIndex2|\n",
      "+--------------+--------------+\n",
      "|           0.0|           1.0|\n",
      "|           1.0|           0.0|\n",
      "|           2.0|           1.0|\n",
      "|           0.0|           2.0|\n",
      "|           0.0|           1.0|\n",
      "|           2.0|           0.0|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sc1.createDataFrame([\n",
    "    (0.0, 1.0),\n",
    "    (1.0, 0.0),\n",
    "    (2.0, 1.0),\n",
    "    (0.0, 2.0),\n",
    "    (0.0, 1.0),\n",
    "    (2.0, 0.0)\n",
    "], [\"categoryIndex1\", \"categoryIndex2\"])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCols=[\"categoryIndex1\", \"categoryIndex2\"],\n",
    "                        outputCols=[\"categoryVec1\", \"categoryVec2\"])\n",
    "model = encoder.fit(df)\n",
    "encoded = model.transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output comprises of 3 values. <br>\n",
    "1. First value indicates the length of the vector.\n",
    "2. Second value indicates an array of indices or positions where non zero entries are found.\n",
    "3. Third value indicates an array that tells which numbers are found in the indices indicated by the array in 2.\n",
    "\n",
    "<br>\n",
    "Example: (2, [1], [1.0]) denotes the vector is of length '2' (two), has a value of 1 present at the index 1 or location 1. Therefore, the one hot vector is '01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-------------+-------------+\n",
      "|categoryIndex1|categoryIndex2| categoryVec1| categoryVec2|\n",
      "+--------------+--------------+-------------+-------------+\n",
      "|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|\n",
      "|           1.0|           0.0|(2,[1],[1.0])|(2,[0],[1.0])|\n",
      "|           2.0|           1.0|    (2,[],[])|(2,[1],[1.0])|\n",
      "|           0.0|           2.0|(2,[0],[1.0])|    (2,[],[])|\n",
      "|           0.0|           1.0|(2,[0],[1.0])|(2,[1],[1.0])|\n",
      "|           2.0|           0.0|    (2,[],[])|(2,[0],[1.0])|\n",
      "+--------------+--------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = OneHotEncoder(inputCol='categoryIndex', outputCol='One-hot-vector')\n",
    "model1 = encoder1.fit(indexed)\n",
    "encoded1 = model1.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+--------------+\n",
      "| id|category|categoryIndex|One-hot-vector|\n",
      "+---+--------+-------------+--------------+\n",
      "|  0|       a|          2.0|     (2,[],[])|\n",
      "|  1|       b|          1.0| (2,[1],[1.0])|\n",
      "|  2|       c|          0.0| (2,[0],[1.0])|\n",
      "|  3|       a|          2.0|     (2,[],[])|\n",
      "|  4|       a|          2.0|     (2,[],[])|\n",
      "|  5|       c|          0.0| (2,[0],[1.0])|\n",
      "+---+--------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f42e622176c297619789989c2c6c0b7f411b349ee1112ea7e5531bb10e594a11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hpe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
