{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators. Each estimator can be fitted to some data using its fit method.\n",
    "\n",
    "Here is a simple example where we fit a RandomForestClassifier to some very basic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [[ 1,  2,  3],[11, 12, 13]]  # 2 samples, 3 features\n",
    "y = [0, 1]  # classes of each sample\n",
    "clf.fit(X, y)\n",
    "RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method generally accepts 2 inputs:\n",
    "\n",
    "The samples matrix (or design matrix) X. The size of X is typically (n_samples, n_features), which means that samples are represented as rows and features are represented as columns.\n",
    "\n",
    "The target values y which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). For unsupervized learning tasks, y does not need to be specified. y is usually 1d array where the i th entry corresponds to the target of the i th sample (row) of X.\n",
    "\n",
    "Both X and y are usually expected to be numpy arrays or equivalent array-like data types, though some estimators work with other formats such as sparse matrices.\n",
    "\n",
    "Once the estimator is fitted, it can be used for predicting target values of new data. You don’t need to re-train the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[14, 15, 16],[4, 5, 6]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, pre-processors and transformers follow the same API as the estimator objects (they actually all inherit from the same BaseEstimator class). The transformer objects don’t have a predict method but rather a transform method that outputs a newly transformed sample matrix X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = [[0, 15],[1, -10]]\n",
    "# scale data according to computed scaling values\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2, 0.4, 0.4],\n",
       "       [0.1, 0.3, 0.9, 0.3],\n",
       "       [0.5, 0.7, 0.5, 0.1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the original example\n",
    "X = [[4, 1, 2, 2],\n",
    "     [1, 3, 9, 3],\n",
    "     [5, 7, 5, 1]]\n",
    "\n",
    "\n",
    "\n",
    "# Manual Method:\n",
    "\n",
    "# get the square root of the sum of squares for each record (\"row\")\n",
    "import numpy as np\n",
    "div = [np.sqrt(np.sum(np.power(X[i], 2))) for i in range(len(X))]\n",
    "\n",
    "# divide each value by its record's respective square root of the sum of squares\n",
    "np.array([X[k] / div[k] for k in range(len(X))])\n",
    "\n",
    "# array([[0.8, 0.2, 0.4, 0.4],\n",
    "#        [0.1, 0.3, 0.9, 0.3],\n",
    "#        [0.5, 0.7, 0.5, 0.1]])\n",
    "\n",
    "\n",
    "\n",
    "# SKLearn API Method:\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "Normalizer().fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8e2474611b83d9571a280a7ba862d36318511be3482fc96112f8467724a795a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
